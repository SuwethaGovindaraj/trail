{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b57127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_provider_combinations(df):\n",
    "\n",
    "    # Ensure columns exist\n",
    "    required_cols = [\n",
    "        \"providertaxid\", \"providernpi\", \n",
    "        \"sel_category\", \"paid_amount_bucket\",\n",
    "        \"audits\", \"findings\", \"nofindings\",\n",
    "        \"op_amount\", \"dispute_count\", \"overturn_count\"\n",
    "    ]\n",
    "\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0   # missing columns default to 0 so algorithm won't break\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Step 1: Derived metrics (dynamic)\n",
    "    # -------------------------------------------------------\n",
    "    df[\"hitrate\"] = df[\"findings\"] / df[\"audits\"].replace(0, np.nan)\n",
    "    df[\"dispute_rate\"] = df[\"dispute_count\"] / df[\"audits\"].replace(0, np.nan)\n",
    "    df[\"overturn_rate\"] = df[\"overturn_count\"] / df[\"findings\"].replace(0, np.nan)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Step 2: Dynamic scoring within each provider\n",
    "    # -------------------------------------------------------\n",
    "    def score_per_provider(group):\n",
    "\n",
    "        metric_cols = [\"hitrate\", \"op_amount\", \"audits\"]\n",
    "\n",
    "        # Compute z-scores only if variation exists\n",
    "        for col in metric_cols:\n",
    "            if group[col].nunique() > 1:\n",
    "                group[col + \"_z\"] = (group[col] - group[col].mean()) / group[col].std()\n",
    "            else:\n",
    "                group[col + \"_z\"] = 0\n",
    "\n",
    "        # Weighted final score (can adjust weights anytime)\n",
    "        group[\"score\"] = (\n",
    "            0.5 * group[\"hitrate_z\"] +\n",
    "            0.3 * group[\"op_amount_z\"] +\n",
    "            0.2 * group[\"audits_z\"]\n",
    "        )\n",
    "\n",
    "        return group\n",
    "\n",
    "    df = df.groupby([\"providertaxid\", \"providernpi\"], group_keys=False).apply(score_per_provider)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Step 3: Classification into buckets\n",
    "    # -------------------------------------------------------\n",
    "    def classify(row):\n",
    "        if row[\"audits\"] < 15:\n",
    "            return \"Insufficient Data – low audit sample\"\n",
    "        if row[\"score\"] > 0.7:\n",
    "            return \"High Performing\"\n",
    "        if 0.4 <= row[\"score\"] <= 0.7:\n",
    "            return \"Moderate Performing\"\n",
    "        if row[\"score\"] < 0.4:\n",
    "            return \"Low Performing\"\n",
    "    \n",
    "    df[\"performance_label\"] = df.apply(classify, axis=1)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Step 4: Insight Generation\n",
    "    # -------------------------------------------------------\n",
    "    def create_insight(row):\n",
    "\n",
    "        if row[\"performance_label\"].startswith(\"Insufficient\"):\n",
    "            return (\n",
    "                f\"Only {row['audits']} audits — not enough data to judge performance \"\n",
    "                f\"in {row['sel_category']} – {row['paid_amount_bucket']}.\"\n",
    "            )\n",
    "\n",
    "        if row[\"performance_label\"] == \"High Performing\":\n",
    "            return (\n",
    "                f\"Strong performance in {row['sel_category']} – {row['paid_amount_bucket']}: \"\n",
    "                f\"Hitrate {row['hitrate']:.2%}, OP ${row['op_amount']:.2f}. \"\n",
    "                f\"Among the best categories for this provider.\"\n",
    "            )\n",
    "\n",
    "        if row[\"performance_label\"] == \"Moderate Performing\":\n",
    "            return (\n",
    "                f\"Average performance in {row['sel_category']} – {row['paid_amount_bucket']}. \"\n",
    "                f\"Hitrate and OP are close to provider's overall average.\"\n",
    "            )\n",
    "\n",
    "        if row[\"performance_label\"] == \"Low Performing\":\n",
    "            return (\n",
    "                f\"Poor performance in {row['sel_category']} – {row['paid_amount_bucket']}: \"\n",
    "                f\"Hitrate {row['hitrate']:.2%}, OP ${row['op_amount']:.2f}. \"\n",
    "                f\"Much lower than other categories for this provider. \"\n",
    "                f\"Recommended for deprioritization/exclusion.\"\n",
    "            )\n",
    "\n",
    "    df[\"insight\"] = df.apply(create_insight, axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def evaluate_provider_performance(df):\n",
    "    # Compute basic metrics\n",
    "    df['hitrate'] = df['findings'] / df['audits']\n",
    "    df['op_per_audit'] = df['overpayment'] / df['audits']\n",
    "    df['dispute_rate'] = df['disputes'] / df['audits']\n",
    "    df['overturn_rate'] = df['overturns'] / df['audits']\n",
    "\n",
    "    # Remove combinations with <15 audits ONLY FROM EVALUATION\n",
    "    df['eligible'] = df['audits'] >= 15\n",
    "\n",
    "    # Standardize metrics provider-wise (TIN + NPI level)\n",
    "    def provider_zscores(x):\n",
    "        metrics = ['hitrate','op_per_audit','overturn_rate']\n",
    "        for m in metrics:\n",
    "            x[f'{m}_z'] = zscore(x[m], ddof=1) if x[m].nunique() > 1 else 0\n",
    "        return x\n",
    "\n",
    "    df = df.groupby(['providertaxid','providernpi']).apply(provider_zscores)\n",
    "\n",
    "    # Overall performance score (higher = better)\n",
    "    df['performance_score'] = (\n",
    "        df['hitrate_z'] * 0.5 +\n",
    "        df['op_per_audit_z'] * 0.3 +\n",
    "        df['overturn_rate_z'] * 0.2\n",
    "    )\n",
    "\n",
    "    # Insights (dynamic – provider-wise quartiles)\n",
    "    def assign_insight(x):\n",
    "        if len(x[x['eligible']]) == 0:\n",
    "            x['insight'] = \"Not enough audit volume to evaluate\"\n",
    "            return x\n",
    "\n",
    "        scores = x.loc[x['eligible'], 'performance_score']\n",
    "        q1, q3 = scores.quantile([0.25, 0.75])\n",
    "\n",
    "        def label(row):\n",
    "            if not row['eligible']:\n",
    "                return \"Low audits — excluded from evaluation\"\n",
    "\n",
    "            if row['performance_score'] >= q3:\n",
    "                return (\"Strong performer — This selection category & paid bucket \"\n",
    "                        \"consistently shows high hitrate, OP and overturn success \"\n",
    "                        \"compared to other combinations for this provider\")\n",
    "\n",
    "            elif row['performance_score'] <= q1:\n",
    "                return (\"Weak performer — This combination underperforms in hitrate, OP \"\n",
    "                        \"and overturn rate compared to other categories for the same provider\")\n",
    "\n",
    "            else:\n",
    "                return (\"Moderate performer — Performance is neither high nor low but \"\n",
    "                        \"should be monitored relative to other categories\")\n",
    "\n",
    "        x['insight'] = x.apply(label, axis=1)\n",
    "        return x\n",
    "\n",
    "    df = df.groupby(['providertaxid','providernpi']).apply(assign_insight)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649bba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. MAIN ALGORITHM — AUTO DETECTS WEAK / STRONG COMBINATIONS\n",
    "# -------------------------------------------------------------\n",
    "def evaluate_provider_performance(df):\n",
    "\n",
    "    # ---- Basic computed metrics ----\n",
    "    df['hitrate'] = df['findings'] / df['audits']\n",
    "    df['op_per_audit'] = df['overpayment'] / df['audits']\n",
    "    df['dispute_rate'] = df['disputes'] / df['audits']\n",
    "    df['overturn_rate'] = df['overturns'] / df['audits']\n",
    "\n",
    "    # ---- Exclude low audit volume (<15) from scoring ----\n",
    "    df['eligible'] = df['audits'] >= 15\n",
    "\n",
    "    # ---- Compute z-scores within each provider ----\n",
    "    def provider_zscores(x):\n",
    "        metrics = ['hitrate', 'op_per_audit', 'overturn_rate']\n",
    "        for m in metrics:\n",
    "            if x[m].nunique() > 1:\n",
    "                x[f'{m}_z'] = zscore(x[m], ddof=1)\n",
    "            else:\n",
    "                x[f'{m}_z'] = 0\n",
    "        return x\n",
    "\n",
    "    df = df.groupby(['providertaxid', 'providernpi']).apply(provider_zscores)\n",
    "\n",
    "    # ---- Weighted dynamic performance score ----\n",
    "    df['performance_score'] = (\n",
    "        df['hitrate_z'] * 0.5 +\n",
    "        df['op_per_audit_z'] * 0.3 +\n",
    "        df['overturn_rate_z'] * 0.2\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # 2. Assign insight category based on provider-level distribution\n",
    "    # -------------------------------------------------------------\n",
    "    def assign_insight(x):\n",
    "        # If provider has zero eligible rows\n",
    "        if len(x[x['eligible']]) == 0:\n",
    "            x['insight'] = \"Not enough audit volume to evaluate\"\n",
    "            return x\n",
    "\n",
    "        eligible_scores = x.loc[x['eligible'], 'performance_score']\n",
    "        q1, q3 = eligible_scores.quantile([0.25, 0.75])\n",
    "\n",
    "        def label(row):\n",
    "            if not row['eligible']:\n",
    "                return \"Low audits (<15) — excluded from evaluation\"\n",
    "\n",
    "            if row['performance_score'] >= q3:\n",
    "                return (\n",
    "                    \"Strong performer — This category shows superior hitrate, \"\n",
    "                    \"higher overpayment recovery per audit, and better overturn success \"\n",
    "                    \"than other categories for this provider.\"\n",
    "                )\n",
    "\n",
    "            elif row['performance_score'] <= q1:\n",
    "                return (\n",
    "                    \"Weak performer — Underperforms in hitrate, overpayment recovery, \"\n",
    "                    \"and overturn rate compared to other categories of the same provider.\"\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                return (\n",
    "                    \"Moderate performer — Average performance; neither strong nor weak. \"\n",
    "                    \"Monitor for future trend.\"\n",
    "                )\n",
    "\n",
    "        x['insight'] = x.apply(label, axis=1)\n",
    "        return x\n",
    "\n",
    "    df = df.groupby(['providertaxid','providernpi']).apply(assign_insight)\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. REPORT GENERATOR — MANAGER FRIENDLY SUMMARY\n",
    "# -------------------------------------------------------------\n",
    "def generate_provider_report(df):\n",
    "\n",
    "    report_dict = {}\n",
    "    grouped = df.groupby(['providertaxid', 'providernpi'])\n",
    "\n",
    "    for (tin, npi), data in grouped:\n",
    "\n",
    "        # Only eligible categories (audits >=15)\n",
    "        eligible = data[data['eligible']]\n",
    "\n",
    "        if eligible.empty:\n",
    "            report_dict[(tin, npi)] = {\n",
    "                \"top_performers\": [],\n",
    "                \"weak_performers\": [],\n",
    "                \"summary\": f\"TIN {tin}, NPI {npi} cannot be evaluated (all categories have <15 audits).\"\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        top = eligible[eligible['insight'].str.contains(\"Strong performer\")]\n",
    "        weak = eligible[eligible['insight'].str.contains(\"Weak performer\")]\n",
    "\n",
    "        # Build readable summary\n",
    "        summary_lines = [\n",
    "            f\"Performance Summary for Provider (TIN: {tin}, NPI: {npi})\",\n",
    "            \"------------------------------------------------------------\"\n",
    "        ]\n",
    "\n",
    "        if not top.empty:\n",
    "            summary_lines.append(\n",
    "                f\"• {len(top)} strong performing categories — Higher hitrate, OP recovery \"\n",
    "                \"and overturn pattern compared to provider's other categories.\"\n",
    "            )\n",
    "        else:\n",
    "            summary_lines.append(\"• No strong performing categories detected.\")\n",
    "\n",
    "        if not weak.empty:\n",
    "            summary_lines.append(\n",
    "                f\"• {len(weak)} weak performing categories — These categories perform \"\n",
    "                \"significantly below the provider's other categories.\"\n",
    "            )\n",
    "        else:\n",
    "            summary_lines.append(\"• No underperforming categories detected.\")\n",
    "\n",
    "        summary_lines.append(f\"• Total categories evaluated: {len(eligible)}\")\n",
    "        summary_lines.append(\"\")\n",
    "\n",
    "        # Store report for this TIN+NPI\n",
    "        report_dict[(tin, npi)] = {\n",
    "            \"top_performers\": top[['sel_category','paid_amount_bucket','audits','hitrate','performance_score','insight']],\n",
    "            \"weak_performers\": weak[['sel_category','paid_amount_bucket','audits','hitrate','performance_score','insight']],\n",
    "            \"summary\": \"\\n\".join(summary_lines)\n",
    "        }\n",
    "\n",
    "    return report_dict\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. RUN THE FULL PIPELINE\n",
    "# -------------------------------------------------------------\n",
    "# df = your_dataframe  # <--- Replace with your real data\n",
    "\n",
    "# evaluated_df = evaluate_provider_performance(df)\n",
    "# provider_reports = generate_provider_report(evaluated_df)\n",
    "\n",
    "# NOW YOU CAN ACCESS:\n",
    "# provider_reports[(TIN, NPI)][\"summary\"]\n",
    "# provider_reports[(TIN, NPI)][\"top_performers\"]\n",
    "# provider_reports[(TIN, NPI)][\"weak_performers\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6b8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
