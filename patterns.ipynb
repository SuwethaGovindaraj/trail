{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Claim Notes Pattern Discovery & Cluster Tagging\n", "This notebook helps you:\n", "1. Load your claims data.\n", "2. Merge and clean the `communication_notes` and `free_flow_opt_note` columns.\n", "3. Cluster similar claim notes.\n", "4. View **top keywords** and **sample notes** for each cluster.\n", "5. Tag clusters as `finding`, `nofinding`, or `cancelled` interactively.\n", "\n", "You can then use these tags to create regex patterns or train a classifier."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import pandas as pd\n", "import re\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.cluster import KMeans\n", "\n", "# --------------------------\n", "# Load your data\n", "# --------------------------\n", "# Replace 'claims.csv' with your file path\n", "df = pd.read_csv('claims.csv')\n", "\n", "# Merge notes\n", "df[\"merged_text\"] = (\n", "    df[\"communication_notes\"].fillna(\"\") + \" \" +\n", "    df[\"free_flow_opt_note\"].fillna(\"\")\n", ")\n", "\n", "# --------------------------\n", "# Cleaning\n", "# --------------------------\n", "def clean_text(text):\n", "    text = str(text).lower()\n", "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n", "    text = re.sub(r'\\s+', ' ', text).strip()\n", "    return text\n", "\n", "df[\"clean_text\"] = df[\"merged_text\"].apply(clean_text)\n", "\n", "df.head()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# --------------------------\n", "# Vectorize & cluster\n", "# --------------------------\n", "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=3, max_df=0.9, stop_words=\"english\")\n", "X = vectorizer.fit_transform(df[\"clean_text\"])\n", "\n", "# Choose cluster count (tweak as needed)\n", "n_clusters = 8\n", "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n", "df[\"cluster\"] = kmeans.fit_predict(X)\n", "\n", "df['cluster'].value_counts().sort_index()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# --------------------------\n", "# Top terms per cluster\n", "# --------------------------\n", "import numpy as np\n", "\n", "def top_terms_for_cluster(cluster_id, top_n=15):\n", "    idx = df[df[\"cluster\"] == cluster_id].index\n", "    if len(idx) == 0:\n", "        return []\n", "    sub_matrix = X[idx]\n", "    mean_tfidf = sub_matrix.mean(axis=0).A1\n", "    terms = vectorizer.get_feature_names_out()\n", "    top_idx = mean_tfidf.argsort()[::-1][:top_n]\n", "    return [(terms[i], mean_tfidf[i]) for i in top_idx]\n", "\n", "for c in range(n_clusters):\n", "    print(f\"\\nCluster {c} (size {len(df[df['cluster']==c])}):\")\n", "    for term, score in top_terms_for_cluster(c):\n", "        print(f\"{term:20s} {score:.4f}\")"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# --------------------------\n", "# Add evidence column: matched top terms from each note's cluster\n", "# --------------------------\n", "def find_matches_in_text(text, terms):\n", "    found = []\n", "    for term in terms:\n", "        if re.search(r'\\b' + re.escape(term) + r'\\b', text):\n", "            found.append(term)\n", "    return found\n", "\n", "# Build dictionary of cluster -> top terms\n", "cluster_top_terms = {c: [t for t, _ in top_terms_for_cluster(c)] for c in range(n_clusters)}\n", "\n", "# Create column with matches\n", "df[\"matched_terms\"] = df.apply(\n", "    lambda row: \"; \".join(find_matches_in_text(row[\"clean_text\"], cluster_top_terms[row[\"cluster\"]])),\n", "    axis=1\n", ")\n", "\n", "df[[\"merged_text\", \"cluster\", \"matched_terms\"]].head()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# --------------------------\n", "# Show sample notes per cluster\n", "# --------------------------\n", "SAMPLES_PER_CLUSTER = 5\n", "for c in range(n_clusters):\n", "    print(f\"\\n=== Cluster {c} ===\")\n", "    sample_notes = df[df['cluster'] == c]['merged_text'].head(SAMPLES_PER_CLUSTER)\n", "    for note in sample_notes:\n", "        print(\"-\", note)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# --------------------------\n", "# Interactive cluster tagging\n", "# --------------------------\n", "cluster_labels = {}\n", "for c in range(n_clusters):\n", "    print(f\"\\nCluster {c} top terms:\")\n", "    for term, score in top_terms_for_cluster(c):\n", "        print(f\"  {term:20s} {score:.4f}\")\n", "    sample_notes = df[df['cluster'] == c]['merged_text'].head(3)\n", "    print(\"\\nSample notes:\")\n", "    for note in sample_notes:\n", "        print(\"-\", note)\n", "    label = input(\"Enter label for this cluster (finding/nofinding/cancelled/unknown): \").strip().lower()\n", "    cluster_labels[c] = label\n", "\n", "# Assign labels back to df\n", "df['pattern_label'] = df['cluster'].map(cluster_labels)\n", "\n", "# Save labeled dataset\n", "df.to_csv('claims_cluster_tagged.csv', index=False)\n", "print(\"\\nSaved tagged data to claims_cluster_tagged.csv\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}